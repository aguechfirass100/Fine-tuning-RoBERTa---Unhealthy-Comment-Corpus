{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AdamW,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch; \n",
    "print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dataset = load_dataset('tweet_eval', 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Don\\\\u2019t forget Mitch Daniels is going to be on Steven Colbert\\\\u2019s show Thursday.  Think this will come up as a topic?', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tweet_dataset['train'][58])\n",
    "# print(tweet_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/second_data/second_train.csv\", encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(\"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/second_data/second_test.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "textID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "selected_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Time of Tweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Age of User",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Population -2020",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Land Area (Km²)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Density (P/Km²)",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "71f54ac0-493f-40da-b321-387c86309bb4",
       "rows": [
        [
         "0",
         "cb774db0d1",
         " I`d have responded, if I were going",
         "I`d have responded, if I were going",
         "neutral",
         "morning",
         "0-20",
         "Afghanistan",
         "38928346",
         "652860.0",
         "60"
        ],
        [
         "1",
         "549e992a42",
         " Sooo SAD I will miss you here in San Diego!!!",
         "Sooo SAD",
         "negative",
         "noon",
         "21-30",
         "Albania",
         "2877797",
         "27400.0",
         "105"
        ],
        [
         "2",
         "088c60f138",
         "my boss is bullying me...",
         "bullying me",
         "negative",
         "night",
         "31-45",
         "Algeria",
         "43851044",
         "2381740.0",
         "18"
        ],
        [
         "3",
         "9642c003ef",
         " what interview! leave me alone",
         "leave me alone",
         "negative",
         "morning",
         "46-60",
         "Andorra",
         "77265",
         "470.0",
         "164"
        ],
        [
         "4",
         "358bd9e861",
         " Sons of ****, why couldn`t they put them on the releases we already bought",
         "Sons of ****,",
         "negative",
         "noon",
         "60-70",
         "Angola",
         "32866272",
         "1246700.0",
         "26"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['text', 'sentiment']]\n",
    "df_train = df_train.rename(columns={'sentiment': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"positive\": 2\n",
    "}\n",
    "\n",
    "df_train[\"label\"] = df_train[\"label\"].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3b17e200-27c0-4598-bba4-6eda2d8056f4",
       "rows": [
        [
         "0",
         " I`d have responded, if I were going",
         "1"
        ],
        [
         "1",
         " Sooo SAD I will miss you here in San Diego!!!",
         "0"
        ],
        [
         "2",
         "my boss is bullying me...",
         "0"
        ],
        [
         "3",
         " what interview! leave me alone",
         "0"
        ],
        [
         "4",
         " Sons of ****, why couldn`t they put them on the releases we already bought",
         "0"
        ],
        [
         "5",
         "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth",
         "1"
        ],
        [
         "6",
         "2am feedings for the baby are fun when he is all smiles and coos",
         "2"
        ],
        [
         "7",
         "Soooo high",
         "1"
        ],
        [
         "8",
         " Both of you",
         "1"
        ],
        [
         "9",
         " Journey!? Wow... u just became cooler.  hehe... (is that possible!?)",
         "2"
        ],
        [
         "10",
         " as much as i love to be hopeful, i reckon the chances are minimal =P i`m never gonna get my cake and stuff",
         "1"
        ],
        [
         "11",
         "I really really like the song Love Story by Taylor Swift",
         "2"
        ],
        [
         "12",
         "My Sharpie is running DANGERously low on ink",
         "0"
        ],
        [
         "13",
         "i want to go to music tonight but i lost my voice.",
         "0"
        ],
        [
         "14",
         "test test from the LG enV2",
         "1"
        ],
        [
         "15",
         "Uh oh, I am sunburned",
         "0"
        ],
        [
         "16",
         " S`ok, trying to plot alternatives as we speak *sigh*",
         "0"
        ],
        [
         "17",
         "i`ve been sick for the past few days  and thus, my hair looks wierd.  if i didnt have a hat on it would look... http://tinyurl.com/mnf4kw",
         "0"
        ],
        [
         "18",
         "is back home now      gonna miss every one",
         "0"
        ],
        [
         "19",
         "Hes just not that into you",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Uh oh, I am sunburned</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S`ok, trying to plot alternatives as we speak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i`ve been sick for the past few days  and thus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hes just not that into you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0                 I`d have responded, if I were going      1\n",
       "1       Sooo SAD I will miss you here in San Diego!!!      0\n",
       "2                           my boss is bullying me...      0\n",
       "3                      what interview! leave me alone      0\n",
       "4    Sons of ****, why couldn`t they put them on t...      0\n",
       "5   http://www.dothebouncy.com/smf - some shameles...      1\n",
       "6   2am feedings for the baby are fun when he is a...      2\n",
       "7                                          Soooo high      1\n",
       "8                                         Both of you      1\n",
       "9    Journey!? Wow... u just became cooler.  hehe....      2\n",
       "10   as much as i love to be hopeful, i reckon the...      1\n",
       "11  I really really like the song Love Story by Ta...      2\n",
       "12       My Sharpie is running DANGERously low on ink      0\n",
       "13  i want to go to music tonight but i lost my vo...      0\n",
       "14                         test test from the LG enV2      1\n",
       "15                              Uh oh, I am sunburned      0\n",
       "16   S`ok, trying to plot alternatives as we speak...      0\n",
       "17  i`ve been sick for the past few days  and thus...      0\n",
       "18         is back home now      gonna miss every one      0\n",
       "19                         Hes just not that into you      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "textID",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Time of Tweet",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Age of User",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Population -2020",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Land Area (Km²)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Density (P/Km²)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "296a2ccf-7f29-414b-b87f-9f5dba674941",
       "rows": [
        [
         "0",
         "f87dea47db",
         "Last session of the day  http://twitpic.com/67ezh",
         "neutral",
         "morning",
         "0-20",
         "Afghanistan",
         "38928346.0",
         "652860.0",
         "60.0"
        ],
        [
         "1",
         "96d74cb729",
         " Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).",
         "positive",
         "noon",
         "21-30",
         "Albania",
         "2877797.0",
         "27400.0",
         "105.0"
        ],
        [
         "2",
         "eee518ae67",
         "Recession hit Veronique Branquinho, she has to quit her company, such a shame!",
         "negative",
         "night",
         "31-45",
         "Algeria",
         "43851044.0",
         "2381740.0",
         "18.0"
        ],
        [
         "3",
         "01082688c6",
         " happy bday!",
         "positive",
         "morning",
         "46-60",
         "Andorra",
         "77265.0",
         "470.0",
         "164.0"
        ],
        [
         "4",
         "33987a8ee5",
         " http://twitpic.com/4w75p - I like it!!",
         "positive",
         "noon",
         "60-70",
         "Angola",
         "32866272.0",
         "1246700.0",
         "26.0"
        ],
        [
         "5",
         "726e501993",
         " that`s great!! weee!! visitors!",
         "positive",
         "night",
         "70-100",
         "Antigua and Barbuda",
         "97929.0",
         "440.0",
         "223.0"
        ],
        [
         "6",
         "261932614e",
         "I THINK EVERYONE HATES ME ON HERE   lol",
         "negative",
         "morning",
         "0-20",
         "Argentina",
         "45195774.0",
         "2736690.0",
         "17.0"
        ],
        [
         "7",
         "afa11da83f",
         " soooooo wish i could, but im in school and myspace is completely blocked",
         "negative",
         "noon",
         "21-30",
         "Armenia",
         "2963243.0",
         "28470.0",
         "104.0"
        ],
        [
         "8",
         "e64208b4ef",
         " and within a short time of the last clue all of them",
         "neutral",
         "night",
         "31-45",
         "Australia",
         "25499884.0",
         "7682300.0",
         "3.0"
        ],
        [
         "9",
         "37bcad24ca",
         " What did you get?  My day is alright.. haven`t done anything yet. leaving soon to my stepsister though!",
         "neutral",
         "morning",
         "46-60",
         "Austria",
         "9006398.0",
         "82400.0",
         "109.0"
        ],
        [
         "10",
         "24c92644a4",
         "My bike was put on hold...should have known that.... argh total bummer",
         "negative",
         "noon",
         "60-70",
         "Azerbaijan",
         "10139177.0",
         "82658.0",
         "123.0"
        ],
        [
         "11",
         "43b390b336",
         " I checked.  We didn`t win",
         "neutral",
         "night",
         "70-100",
         "Bahamas",
         "393244.0",
         "10010.0",
         "39.0"
        ],
        [
         "12",
         "69d6b5d93e",
         " .. and you`re on twitter! Did the tavern bore you that much?",
         "neutral",
         "morning",
         "0-20",
         "Bahrain",
         "1701575.0",
         "760.0",
         "2239.0"
        ],
        [
         "13",
         "5c1e0b61a1",
         "I`m in VA for the weekend, my youngest son turns 2 tomorrow......it makes me kinda sad, he is getting so big, check out my twipics",
         "negative",
         "noon",
         "21-30",
         "Bangladesh",
         "164689383.0",
         "130170.0",
         "1265.0"
        ],
        [
         "14",
         "504e45d9d9",
         "Its coming out the socket  I feel like my phones hole is not a virgin. That`s how loose it is... :`(",
         "negative",
         "night",
         "31-45",
         "Barbados",
         "287375.0",
         "430.0",
         "668.0"
        ],
        [
         "15",
         "ae93ad52a0",
         "So hot today =_=  don`t like it and i hate my new timetable, having such a bad week",
         "negative",
         "morning",
         "46-60",
         "Belarus",
         "9449323.0",
         "202910.0",
         "47.0"
        ],
        [
         "16",
         "9fce30159a",
         " Miss you",
         "negative",
         "noon",
         "60-70",
         "Belgium",
         "11589623.0",
         "30280.0",
         "383.0"
        ],
        [
         "17",
         "00d5195223",
         "Cramps . . .",
         "negative",
         "night",
         "70-100",
         "Belize",
         "397628.0",
         "22810.0",
         "17.0"
        ],
        [
         "18",
         "33f19050cf",
         " you guys didn`t say hi or answer my questions yesterday  but nice songs.",
         "positive",
         "morning",
         "0-20",
         "Benin",
         "12123200.0",
         "112760.0",
         "108.0"
        ],
        [
         "19",
         "f7718b3c23",
         "I`m going into a spiritual stagnentation, its exploding my ego!. I now realise, i`m not all that great. and I`m ok with that.",
         "neutral",
         "noon",
         "21-30",
         "Bhutan",
         "771608.0",
         "38100.0",
         "20.0"
        ],
        [
         "20",
         "9ef44428d0",
         "Stupid storm. No river for us tonight",
         "negative",
         "night",
         "31-45",
         "Bolivia",
         "11673021.0",
         "1083300.0",
         "11.0"
        ],
        [
         "21",
         "be634ebeb0",
         "My dead grandpa pays more attention to me than you do",
         "negative",
         "morning",
         "46-60",
         "Bosnia and Herzegovina",
         "3280819.0",
         "51000.0",
         "64.0"
        ],
        [
         "22",
         "3dcf4f7e13",
         "... need retail therapy, bad. AHHH.....gimme money geebus",
         "negative",
         "noon",
         "60-70",
         "Botswana",
         "2351627.0",
         "566730.0",
         "4.0"
        ],
        [
         "23",
         "f0ef04109b",
         "about to go to sleep",
         "neutral",
         "night",
         "70-100",
         "Brazil",
         "212559417.0",
         "8358140.0",
         "25.0"
        ],
        [
         "24",
         "8be365118e",
         " you are lame  go make me breakfast!!",
         "negative",
         "morning",
         "0-20",
         "Brunei",
         "437479.0",
         "5270.0",
         "83.0"
        ],
        [
         "25",
         "c50bdd4567",
         " thats so cool",
         "positive",
         "noon",
         "21-30",
         "Bulgaria",
         "6948445.0",
         "108560.0",
         "64.0"
        ],
        [
         "26",
         "334954f215",
         "hey peoples, dont you just hate being grounded haha, im just sat eating an apple and watching death note (some anime)",
         "neutral",
         "night",
         "31-45",
         "Burkina Faso",
         "20903273.0",
         "273600.0",
         "76.0"
        ],
        [
         "27",
         "b783916431",
         "Huh, another ScarePoint coding Sunday",
         "neutral",
         "morning",
         "46-60",
         "Burundi",
         "11890784.0",
         "25680.0",
         "463.0"
        ],
        [
         "28",
         "1fa8e6ad66",
         " look who I found just for you  --->  http://twitter.com/DJT2009",
         "positive",
         "noon",
         "60-70",
         "Côte d'Ivoire",
         "26378274.0",
         "318000.0",
         "83.0"
        ],
        [
         "29",
         "be38b29042",
         "No AC, the fan doesnt swing our way ... we are sweating it out on a hot humid day",
         "negative",
         "night",
         "70-100",
         "Cabo Verde",
         "555987.0",
         "4030.0",
         "138.0"
        ],
        [
         "30",
         "95701e8ed9",
         " guess that depends on if you want to be on the jury",
         "neutral",
         "morning",
         "0-20",
         "Cambodia",
         "16718965.0",
         "176520.0",
         "95.0"
        ],
        [
         "31",
         "4dd58ecd2c",
         "resorted to eating Mickey Ds ALONE.",
         "neutral",
         "noon",
         "21-30",
         "Cameroon",
         "26545863.0",
         "472710.0",
         "56.0"
        ],
        [
         "32",
         "cf553cccd5",
         "There is a faux gothy chick looking at me, sorry I am not going to camden and I like pop-punk and jimmy eat world",
         "neutral",
         "night",
         "31-45",
         "Canada",
         "37742154.0",
         "9093510.0",
         "4.0"
        ],
        [
         "33",
         "55c69c2d52",
         " did he ask for your Twitter ID? Your sun sign?",
         "neutral",
         "morning",
         "46-60",
         "Central African Republic",
         "4829767.0",
         "622980.0",
         "8.0"
        ],
        [
         "34",
         "9b1a52cc02",
         " where`d you go!",
         "neutral",
         "noon",
         "60-70",
         "Chad",
         "16425864.0",
         "1259200.0",
         "13.0"
        ],
        [
         "35",
         "cce5c4744a",
         "Watching Body of Lies...good film",
         "positive",
         "night",
         "70-100",
         "Chile",
         "19116201.0",
         "743532.0",
         "26.0"
        ],
        [
         "36",
         "c7f9d559e2",
         "Happy mothers day mumm  xoxo",
         "positive",
         "morning",
         "0-20",
         "China",
         "1439323776.0",
         "9388211.0",
         "153.0"
        ],
        [
         "37",
         "3d2478db59",
         "So I really need to put the laptop down & start getting ready for  shindig...But I`ve missed my TwitterLoves all day",
         "neutral",
         "noon",
         "21-30",
         "Colombia",
         "50882891.0",
         "1109500.0",
         "46.0"
        ],
        [
         "38",
         "6d846d7d50",
         " I`m sorry  at least it`s Friday?",
         "negative",
         "night",
         "31-45",
         "Comoros",
         "869601.0",
         "1861.0",
         "467.0"
        ],
        [
         "39",
         "599f51af6b",
         "feels sorry every time I`m printing out, I use like 200 new papers",
         "negative",
         "morning",
         "46-60",
         "Congo (Congo-Brazzaville)",
         "5518087.0",
         "342000.0",
         "16.0"
        ],
        [
         "40",
         "87daa62920",
         " 4n? ma rog  never heard of it  esti beat acum? u tweet too much",
         "negative",
         "noon",
         "60-70",
         "Costa Rica",
         "5094118.0",
         "51060.0",
         "100.0"
        ],
        [
         "41",
         "6506dc55ff",
         " I always forget SOMETHING when I travel. I am at Newark airport.",
         "neutral",
         "night",
         "70-100",
         "Croatia",
         "4105267.0",
         "55960.0",
         "73.0"
        ],
        [
         "42",
         "746d87f93e",
         "Should have left car and walked home! I might need someone to rescue me with petrol! Light flashing",
         "neutral",
         "morning",
         "0-20",
         "Cuba",
         "11326616.0",
         "106440.0",
         "106.0"
        ],
        [
         "43",
         "ef7ef8e474",
         "i`m only updating this so that brett`s phone beeps  but really.. looking at wedding stuff. again.for the next five months.",
         "neutral",
         "noon",
         "21-30",
         "Cyprus",
         "1207359.0",
         "9240.0",
         "131.0"
        ],
        [
         "44",
         "d3d7b13278",
         " Hi there.  I agree!  Small children should be running about happy, not breaking down in tears",
         "positive",
         "night",
         "31-45",
         "Czechia (Czech Republic)",
         "10708981.0",
         "77240.0",
         "139.0"
        ],
        [
         "45",
         "ddc07db84e",
         "  Hope ur havin fun in da club",
         "positive",
         "morning",
         "46-60",
         "Democratic Republic of the Congo",
         "89561403.0",
         "2267050.0",
         "40.0"
        ],
        [
         "46",
         "67afe60d31",
         "i miss my old phone it worked so good until i dropped it  i want a new one for my birthday...",
         "neutral",
         "noon",
         "60-70",
         "Denmark",
         "5792202.0",
         "42430.0",
         "137.0"
        ],
        [
         "47",
         "17d18ba9ef",
         "thinks SG is wonderful",
         "positive",
         "night",
         "70-100",
         "Djibouti",
         "988000.0",
         "23180.0",
         "43.0"
        ],
        [
         "48",
         "ab57d75f20",
         "  im really sorry i know wallah how u feel this life is shittttttttt",
         "negative",
         "morning",
         "0-20",
         "Dominica",
         "71986.0",
         "750.0",
         "96.0"
        ],
        [
         "49",
         "f0acd25d8e",
         "Not happy",
         "negative",
         "noon",
         "21-30",
         "Dominican Republic",
         "10847910.0",
         "48300.0",
         "225.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 4815
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346.0</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797.0</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044.0</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272.0</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4815 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               text sentiment  \\\n",
       "0     f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1     96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2     eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3     01082688c6                                        happy bday!  positive   \n",
       "4     33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "...          ...                                                ...       ...   \n",
       "4810         NaN                                                NaN       NaN   \n",
       "4811         NaN                                                NaN       NaN   \n",
       "4812         NaN                                                NaN       NaN   \n",
       "4813         NaN                                                NaN       NaN   \n",
       "4814         NaN                                                NaN       NaN   \n",
       "\n",
       "     Time of Tweet Age of User      Country  Population -2020  \\\n",
       "0          morning        0-20  Afghanistan        38928346.0   \n",
       "1             noon       21-30      Albania         2877797.0   \n",
       "2            night       31-45      Algeria        43851044.0   \n",
       "3          morning       46-60      Andorra           77265.0   \n",
       "4             noon       60-70       Angola        32866272.0   \n",
       "...            ...         ...          ...               ...   \n",
       "4810           NaN         NaN          NaN               NaN   \n",
       "4811           NaN         NaN          NaN               NaN   \n",
       "4812           NaN         NaN          NaN               NaN   \n",
       "4813           NaN         NaN          NaN               NaN   \n",
       "4814           NaN         NaN          NaN               NaN   \n",
       "\n",
       "      Land Area (Km²)  Density (P/Km²)  \n",
       "0            652860.0             60.0  \n",
       "1             27400.0            105.0  \n",
       "2           2381740.0             18.0  \n",
       "3               470.0            164.0  \n",
       "4           1246700.0             26.0  \n",
       "...               ...              ...  \n",
       "4810              NaN              NaN  \n",
       "4811              NaN              NaN  \n",
       "4812              NaN              NaN  \n",
       "4813              NaN              NaN  \n",
       "4814              NaN              NaN  \n",
       "\n",
       "[4815 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['text', 'sentiment']]\n",
    "df_test = df_test.rename(columns={'sentiment': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"positive\": 2\n",
    "}\n",
    "\n",
    "df_test[\"label\"] = df_test[\"label\"].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281\n"
     ]
    }
   ],
   "source": [
    "print(df_test[\"label\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.dropna(subset=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"label\"] = df_test[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "130e2685-f44c-4223-86bf-066406a87b82",
       "rows": [
        [
         "0",
         "Last session of the day  http://twitpic.com/67ezh",
         "1"
        ],
        [
         "1",
         " Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).",
         "2"
        ],
        [
         "2",
         "Recession hit Veronique Branquinho, she has to quit her company, such a shame!",
         "0"
        ],
        [
         "3",
         " happy bday!",
         "2"
        ],
        [
         "4",
         " http://twitpic.com/4w75p - I like it!!",
         "2"
        ],
        [
         "5",
         " that`s great!! weee!! visitors!",
         "2"
        ],
        [
         "6",
         "I THINK EVERYONE HATES ME ON HERE   lol",
         "0"
        ],
        [
         "7",
         " soooooo wish i could, but im in school and myspace is completely blocked",
         "0"
        ],
        [
         "8",
         " and within a short time of the last clue all of them",
         "1"
        ],
        [
         "9",
         " What did you get?  My day is alright.. haven`t done anything yet. leaving soon to my stepsister though!",
         "1"
        ],
        [
         "10",
         "My bike was put on hold...should have known that.... argh total bummer",
         "0"
        ],
        [
         "11",
         " I checked.  We didn`t win",
         "1"
        ],
        [
         "12",
         " .. and you`re on twitter! Did the tavern bore you that much?",
         "1"
        ],
        [
         "13",
         "I`m in VA for the weekend, my youngest son turns 2 tomorrow......it makes me kinda sad, he is getting so big, check out my twipics",
         "0"
        ],
        [
         "14",
         "Its coming out the socket  I feel like my phones hole is not a virgin. That`s how loose it is... :`(",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and within a short time of the last clue all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What did you get?  My day is alright.. haven`...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>My bike was put on hold...should have known th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I checked.  We didn`t win</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.. and you`re on twitter! Did the tavern bore...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I`m in VA for the weekend, my youngest son tur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Its coming out the socket  I feel like my phon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0   Last session of the day  http://twitpic.com/67ezh      1\n",
       "1    Shanghai is also really exciting (precisely -...      2\n",
       "2   Recession hit Veronique Branquinho, she has to...      0\n",
       "3                                         happy bday!      2\n",
       "4              http://twitpic.com/4w75p - I like it!!      2\n",
       "5                     that`s great!! weee!! visitors!      2\n",
       "6             I THINK EVERYONE HATES ME ON HERE   lol      0\n",
       "7    soooooo wish i could, but im in school and my...      0\n",
       "8    and within a short time of the last clue all ...      1\n",
       "9    What did you get?  My day is alright.. haven`...      1\n",
       "10  My bike was put on hold...should have known th...      0\n",
       "11                          I checked.  We didn`t win      1\n",
       "12   .. and you`re on twitter! Did the tavern bore...      1\n",
       "13  I`m in VA for the weekend, my youngest son tur...      0\n",
       "14  Its coming out the socket  I feel like my phon...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['text', 'label']]\n",
    "df_test = df_test[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = pd.concat([tweet_dataset['train'].to_pandas(), df_train], ignore_index=True)\n",
    "merged_test = pd.concat([tweet_dataset['test'].to_pandas(), df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing & tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]['text']\n",
    "        label = self.data[idx]['label']\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = merged_train.to_dict(orient=\"records\")\n",
    "merged_test = merged_test.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetDataset(merged_train, tokenizer)\n",
    "test_dataset = TweetDataset(merged_test, tokenizer)\n",
    "val_dataset = TweetDataset(tweet_dataset['validation'], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=16):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        pass\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            \n",
    "        return loss, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, logits = self(**batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, batch['labels'], task='multiclass', num_classes=3)\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': acc}, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, logits = self(**batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, batch['labels'], task='multiclass', num_classes=3)\n",
    "        self.log_dict({'test_loss': loss, 'test_acc': acc})\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type             | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | roberta    | RobertaModel     | 124 M  | eval \n",
      "1 | classifier | Linear           | 2.3 K  | train\n",
      "2 | loss_fn    | CrossEntropyLoss | 0      | train\n",
      "--------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "498.592   Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "228       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22%|██▏       | 1980/9137 [04:04<14:42,  8.11it/s, v_num=3]      "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_23079/3387846227.py\", line 17, in __getitem__\n    encoding = self.tokenizer(\n        text,\n    ...<3 lines>...\n        return_tensors='pt'\n    )\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py\", line 2877, in __call__\n    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py\", line 2937, in _call_one\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      4\u001b[39m checkpoint_callback = ModelCheckpoint(\n\u001b[32m      5\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     save_top_k=\u001b[32m1\u001b[39m,\n\u001b[32m      8\u001b[39m     filename=\u001b[33m'\u001b[39m\u001b[33mbest-checkpoint\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m trainer = pl.Trainer(\n\u001b[32m     12\u001b[39m     max_epochs=\u001b[32m5\u001b[39m,\n\u001b[32m     13\u001b[39m     accelerator=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     precision=\u001b[33m'\u001b[39m\u001b[33m16-mixed\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     callbacks=[checkpoint_callback]\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     50\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:575\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    569\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    571\u001b[39m     ckpt_path,\n\u001b[32m    572\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    573\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:982\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    977\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    987\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1026\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1025\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:282\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    281\u001b[39m     dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[32m    285\u001b[39m     batch_idx = \u001b[38;5;28mself\u001b[39m.batch_idx + \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batches\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._start_profiler()\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ITERATOR_RETURN:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/pytorch_lightning/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28mself\u001b[39m._consumed[i] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1480\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m   1479\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1505\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/_utils.py:733\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mValueError\u001b[39m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_23079/3387846227.py\", line 17, in __getitem__\n    encoding = self.tokenizer(\n        text,\n    ...<3 lines>...\n        return_tensors='pt'\n    )\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py\", line 2877, in __call__\n    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n  File \"/home/AGFirass/Documents/Github/Fine-tuning-RoBERTa---Unhealthy-Comment-Corpus/venv/lib/python3.13/site-packages/transformers/tokenization_utils_base.py\", line 2937, in _call_one\n    raise ValueError(\n    ...<2 lines>...\n    )\nValueError: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\n"
     ]
    }
   ],
   "source": [
    "dm = TweetDataModule(batch_size=8)\n",
    "model = SentimentClassifier()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_top_k=1,\n",
    "    filename='best-checkpoint'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='auto',\n",
    "    precision='16-mixed',\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(dataloaders=dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.roberta(**encoding)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = model.classifier(pooled_output)\n",
    "        \n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = \"I love how this model understands emojis! 😍\"\n",
    "sample_text = \"RIP Duo, he would have loved this emotional manipulation.\"\n",
    "probabilities = predict_sentiment(sample_text, model, tokenizer)\n",
    "predicted_class = torch.argmax(probabilities).item()\n",
    "print(f\"Predicted sentiment: {['negative', 'neutral', 'positive'][predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
